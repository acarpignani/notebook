[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Data Science",
    "section": "",
    "text": "Introduction\nWelcome to the public repository of the enhancement class on R for Data Science offered at The Bedford Sixth Form. In this page you will find the list of all data set that are going to be used in the course, as well as useful information, and a brief note of all the topics covered in each lesson.\n\nAim of this course\nThe aim of this course is to give a thorough and opinionated introduction to R using the magnificent IDE RStudio, to show how the program excellently performs data analysis on different data sets, to introduce to the use of the meta-package tidyverse to perform exploratory data analysis, clean and reshape the data, and to give an introduction to machine learning algorithms using the meta-package tidymodels.\nIn the second part of the course, when the students have acquired the basic syntax of R, the course will move onto an individual project in which every participant can collect suitable data and analyse the data to answer a statistical question on a topic of their choice, and write a full reproducible report to show their findings. The project may be published on RPubs and can be included in the student’s portfolio, to show potential employers or to university their ability to use the software and to analyse data.\n\n\nPrerequisites to follow this course\nThis course has basically no prerequisites, except the notions of mathematics and statistics from any GCSE Mathematics course. In particular, the learner is assumed to know the following statistical tools: mean, mode, median, range, interquartile range, box-and-whiskers plot, histogram, bar chart. Any other statistical instrument that might be useful will be briefly recalled during the course.\n\n\nInstall R and RStudio\n\nTo install R, it suffices to follow the link to the Comprehensive R Archive Network (CRAN) repository and to install R clicking on the Download R for &lt;your-base-system&gt;.\n\nIn this course we will also assume that you have installed the RStudio IDE. This open-source, integrated desktop environment makes it possible for all R users to have a common R interface, which is greatly enhanced over the R’s basic command line interface.\n\nInstallation of RStudio is straightforward in most cases. The RStudio web site has links to the necessary files to download.\n\n\n\nBibliography\nI am adding below some websites that you might find useful to look for data.\n\nThe UC Irvine Machine Learning Repository (UCI Repository) contains lots of data sets that can be used to do machine learning.\nTidyTuesday is a project of the R community that aims to provide weekly real world data sets to tidy and analyse.\nKaggle is a great place to find little useful challenges to do. We shall see some of these challenges in our course, but you may always want to attempt one of them of your own. If there is a general consensus on a particular challenge, that could also be done as a team.\nThe World Bank contains a wealth of data that can be analysed.\n\nAlso you may wish to check the little publications that I have made on RPubs."
  },
  {
    "objectID": "r-basics.html",
    "href": "r-basics.html",
    "title": "Introduction to R",
    "section": "",
    "text": "There are several ways to interact with R. The primary one will be through the command line, also known as console. The command line in RStudio is in the console panel. The name comes from it being the place where one types in commands.\n\n\n\nAn alternative way to interact with R is by typing all the code in an R script. In RStudio, click File &gt; New File &gt; R Script to open a new script. Changing line in the script won’t run the code, however. In order to run the line of code you need to press Ctrl + ENTER in Windows and cmd + ENTER in Mac. There are also commands to run the whole script, but let’s just keep it simple for the time being.\n\n\n\nIn first instance, R is a very powerful and fancy calculator. Typing in the command line numerical expressions with the usual mathematical operations, we get the results we expect:\n\n2 + 3\n\n[1] 5\n\n\nThe four operations in R are +, -, * and / and R follows the usual mathematical rules for the priority of the operations (the one that some people call BIDMAS).\n\n5 * 2 - 12 / 4\n\n[1] 7\n\n\nThe order of the operations can be altered using brackets, like so:\n\n(4 + 5 * 2) / (8 / 2 - 3)\n\n[1] 14\n\n\nBesides the four operations, R has some very useful other operations, such as the integer division %/% and the modulo %% of two numbers. The integer division gives the quotient of the division and the modulo gives the remainder of the division, like so:\n\n25 %/% 4\n\n[1] 6\n\n\n\n25 %% 4\n\n[1] 1\n\n\nIn fact, we have 25 = 6 x 4 + 1.\nWe can also perform powers with R. The syntax is a ^ n to produce a to the power of n. For example,\n\n3 ^ 4\n\n[1] 81\n\n\n\n\nR is also equipped with two special “values” that represent “true” and “false”. These are called the Boolean values and denoted in R by TRUE or T, and FALSE or F. These two special values can be joined together through the logical operations which are: and, or, and not. In R, and is represented by &, or by | and not by !. So, for example, we have:\n\nTRUE & FALSE\n\n[1] FALSE\n\nTRUE | FALSE\n\n[1] TRUE\n\n!FALSE\n\n[1] TRUE\n\n\nAgain, logical values can be linked together with brackets.\n\n\n\n\nOnce started understanding how R works with operations and numbers, we wish to start assigning values to variables and working with variables instead. R provides a special command to assign a value to a variable: &lt;-. This is called the assignment operator. For example\n\nx &lt;- 10\ny &lt;- 2.5\n\nx * y\n\n[1] 25\n\n\nYou don’t have to use a single letter to name a variable. Conversely, it is advisable not to do so, but to use meaningful words that recall the meaning of that variable. For example, to record the height and weight of an individual, we could use\n\nheight &lt;- 150\nweight &lt;- 65\n\n\n\n\n\n\n\nOn the names of variables\n\n\n\nA variable name must start with a letter, but it can contain also numbers, full stop, and underscore after the first letter. There are several different schools of thought about which is the best way to denote variables. In the past, I would have probably chosen a notation such as my.variable to indicate a variable, but after having coded for a long time alongside the magnificent data scientists and software engineers at Posit (former RStudio), I am now more used to a notation like my_variable which I do recommend.\n\n\nWe can work with variables joining them together with the usual operations. For example:\n\nbank_account &lt;- 100\ndeposit &lt;-  30\n\nbank_account &lt;- bank_account + deposit\n\nbank_account\n\n[1] 130\n\n\n\n\n\nUnlike programming languages such as C, Pascal, etc, R doesn’t require to state in advance the type of the variables but it assigns the data type automatically. In most simple cases, the user doesn’t really need bother about the data types, but in some cases, and especially when one starts working with data frames and working in machine learning, awareness of the variable type is very important, and the ability to change data type is paramount.\nR has many different data types. In what follows we shall go through the most important of them.\n\n\nThe most common data type is double, i.e. decimal numbers described using floating point values. Any number is stored in R as a double, unless otherwise specified. So, for example, the following are double.\n\na &lt;- 5\nb &lt;- 2.2\n\nTo see the type of these variable, we can use the command typeof. So\n\ntypeof(a)\n\n[1] \"double\"\n\ntypeof(b)\n\n[1] \"double\"\n\n\n\n\n\nTo tell R that we want the number to be an integer we need to add an L after the number during the assignment. For example\n\nn &lt;- 5L\n\nis an integer. To see this, let’s use again the typeof command:\n\ntypeof(n)\n\n[1] \"integer\"\n\n\nDouble and integer are referred to as numeric variables.\n\n\n\nR has also the possibility to store complex numbers. This is done using the key i for the imaginary unit. For example:\n\nz &lt;- 2 + 3i\nw &lt;- 5 + 2i\n\nIf variables are complex, R knows how to adapt the arithmetic operations to complex numbers. For example,\n\nz + w\n\n[1] 7+5i\n\n2 * z\n\n[1] 4+6i\n\n(1 - 2i) * w\n\n[1] 9-8i\n\n\n\n\n\nAs we have mentioned before, R has two Boolean values (true and false). Their type is logical.\n\np &lt;- TRUE\ntypeof(p)\n\n[1] \"logical\"\n\n\n\n\n\nAnother common type is character, which is the data type of characters and strings. To assign a character type to a variable, we use the quotation marks: both the single ' and the double \" quotation marks work.\n\nchar &lt;- \"Hello, world!\"\ntypeof(char)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBeside typeof, there is another command that shows the type of a variable: class.\n\n\n\n\n\n\nIn R we can use comparison operators to compare variables and return a logical value. The comparison operators are\n\n\n\nOperator\nName\nSyntax\n\n\n\n\n==\nequal\na == b\n\n\n!=\ndifferent\na != b\n\n\n&lt;=\nsmaller than, or equal to\na &lt;= b\n\n\n&lt;\nsmaller than\na &lt; b\n\n\n&gt;=\ngreater than, or equal to\na &gt;= b\n\n\n&gt;\ngreater than\na &gt; b\n\n\n\nFor example,\n\n5 &gt; 3\n\n[1] TRUE\n\n6 &lt; 3\n\n[1] FALSE\n\n\n\n\n\nBesides google searching and visiting Stack Overflow, there are some build-in functions to get help from R. In fact, most of the R functions have documentation and examples. To access the documentation of a function foo we can either use ?foo or help(foo). For example,\n\nhelp(vector)\n\nopens the documentation with title Vectors - Creation, Coercion, etc."
  },
  {
    "objectID": "r-basics.html#rs-command-line",
    "href": "r-basics.html#rs-command-line",
    "title": "Introduction to R",
    "section": "",
    "text": "There are several ways to interact with R. The primary one will be through the command line, also known as console. The command line in RStudio is in the console panel. The name comes from it being the place where one types in commands.\nIn first instance, R is a very powerful and fancy calculator. Typing in the command line numerical expressions with the usual mathematical operations, we get the results we expect:\n\n2 + 3\n\n[1] 5\n\n\nThe four operations in R are +, -, * and / and R follows the usual mathematical rules for the priority of the operations (the one that some people call BIDMAS).\n\n5 * 2 - 12 / 4\n\n[1] 7\n\n\nThe order of the operations can be altered using brackets, like so:\n\n(4 + 5 * 2) / (8 / 2 - 3)\n\n[1] 14\n\n\nBesides the four operations, R has some very useful other operations, such as the integer division %/% and the modulo %% of two numbers. The integer division gives the quotient of the division and the modulo gives the remainder of the division, like so:\n\n25 %/% 4\n\n[1] 6\n\n\n\n25 %% 4\n\n[1] 1\n\n\nIn fact:\n\n25 = 6 \\times 4 + 1\n\nWe can also perform powers with R. The syntax is a ^ n to produce a^n. For example,\n\n3 ^ 4\n\n[1] 81\n\n\n\n\nR is also equipped with two special “numbers” that represent “TRUE” and “FALSE”. These are TRUE or T and FALSE or F. These two special values can be joined together through the logical operations which are: and, or, and not. In R, and is represented by &, or by | and not by !. So, for example, we have:\n\nTRUE & FALSE\n\n[1] FALSE\n\nTRUE | FALSE\n\n[1] TRUE\n\n!FALSE\n\n[1] TRUE\n\n\nAgain, logical values can be linked together with brackets."
  },
  {
    "objectID": "r-basics.html#r-scripts",
    "href": "r-basics.html#r-scripts",
    "title": "Introduction to R",
    "section": "",
    "text": "Before going ahead and introducing variables, it is convenient to start putting our work into an R Script. In RStudio, click File &gt; New File &gt; R Script to open a new script. Changing line in the script won’t run the code, however. In order to run the line of code you may press Ctrl + ENTER in Windows and cmd + ENTER in Mac. There are also commands to run the whole script, but let’s just keep it simple for the time being.\n\n\nOnce started understanding how R works with operations and numbers, we wish to start assigning values to variables and working with variables instead. R provides a special command to assign a value to a variable: &lt;-. This is called the assignment operator. For example\n\nx &lt;- 10\ny &lt;- 2.5\n\nx * y\n\n[1] 25\n\n\nYou don’t have to use a single letter to name a variable. Conversely, it is advisable not to do so, but to use meaningful words that recall the meaning of that variable. For example, to record the height and weight of an individual, we could use\n\nheight &lt;- 150\nweight &lt;- 65\n\n\n\n\n\n\n\nOn the names of variables\n\n\n\nA variable name must start with a letter, but it can contain also numbers, full stop, and underscore after the first letter. There are several different schools of thought about which is the best way to denote variables. In the past, I would have probably chosen a notation such as my.variable to indicate a variable, but after having coded for a long time alongside the magnificent data scientists and software engineers at Posit (former RStudio), I am now more used to a notation like my_variable which I do recommend.\n\n\nWe can work with variables joining them together with the usual operations. For example:\n\nbank_account &lt;- 100\ndeposit &lt;-  30\n\nbank_account &lt;- bank_account + deposit\n\nbank_account\n\n[1] 130\n\n\n\n\n\nR is a statistical software and in statistics a variable scarcely has only one value, but it is generally given as a list of values (measures). For example, one could have a variable age of the ages of all the employees of a small business. To store this in R, we can use the command c which stands for concatenate. For example\n\nages &lt;- c(25, 33, 45, 37, 28, 23, 42, 58, 29)\n\nNow the variable age is a vector. Let’s find out the length of this vector.\n\nlength(ages)\n\n[1] 9\n\n\nWe may also want to find out the average age of the employees of the business. This can be done with the command mean. E.g.\n\nmean(ages)\n\n[1] 35.55556\n\n\nOther statistical operations are median to calculate the median, IQR to find the interquartile range, sd to find the standard deviation and summary to show a five number summary of the variable, i.e. the minimum, lower quartile, median, upper quartile and maximum in the vector. The function summary also shows the mean.\n\nsummary(ages)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.00   28.00   33.00   35.56   42.00   58.00 \n\n\nIt is interesting to immediately notice that R functions may give different outcomes depending on the type of the variable. We shall come back to the type of a variable, but for the moment let’s just say that we consider an employee to be a junior employee if their age is below 33 years. To check whether the ages are below 33 we can use the normal order operations &lt; and &gt;.\n\nis_junior &lt;- ages &lt;= 33\nis_junior\n\n[1]  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\n\nIf we now run the summary command on the variable is_junior we no longer get a five number summary because the variable is_junior is not numeric.\n\nsummary(is_junior)\n\n   Mode   FALSE    TRUE \nlogical       4       5"
  },
  {
    "objectID": "r-basics.html#operations-in-r",
    "href": "r-basics.html#operations-in-r",
    "title": "Introduction to R",
    "section": "",
    "text": "In first instance, R is a very powerful and fancy calculator. Typing in the command line numerical expressions with the usual mathematical operations, we get the results we expect:\n\n2 + 3\n\n[1] 5\n\n\nThe four operations in R are +, -, * and / and R follows the usual mathematical rules for the priority of the operations (the one that some people call BIDMAS).\n\n5 * 2 - 12 / 4\n\n[1] 7\n\n\nThe order of the operations can be altered using brackets, like so:\n\n(4 + 5 * 2) / (8 / 2 - 3)\n\n[1] 14\n\n\nBesides the four operations, R has some very useful other operations, such as the integer division %/% and the modulo %% of two numbers. The integer division gives the quotient of the division and the modulo gives the remainder of the division, like so:\n\n25 %/% 4\n\n[1] 6\n\n\n\n25 %% 4\n\n[1] 1\n\n\nIn fact:\n\n25 = 6 \\times 4 + 1\n\nWe can also perform powers with R. The syntax is a ^ n to produce a^n. For example,\n\n3 ^ 4\n\n[1] 81\n\n\n\n\nR is also equipped with two special “numbers” that represent “TRUE” and “FALSE”. These are TRUE or T and FALSE or F. These two special values can be joined together through the logical operations which are: and, or, and not. In R, and is represented by &, or by | and not by !. So, for example, we have:\n\nTRUE & FALSE\n\n[1] FALSE\n\nTRUE | FALSE\n\n[1] TRUE\n\n!FALSE\n\n[1] TRUE\n\n\nAgain, logical values can be linked together with brackets.\n\n\n\nOnce started understanding how R works with operations and numbers, we wish to start assigning values to variables and working with variables instead. R provides a special command to assign a value to a variable: &lt;-. This is called the assignment operator. For example\n\nx &lt;- 10\ny &lt;- 2.5\n\nx * y\n\n[1] 25\n\n\nYou don’t have to use a single letter to name a variable. Conversely, it is advisable not to do so, but to use meaningful words that recall the meaning of that variable. For example, to record the height and weight of an individual, we could use\n\nheight &lt;- 150\nweight &lt;- 65\n\n\n\n\n\n\n\nOn the names of variables\n\n\n\nA variable name must start with a letter, but it can contain also numbers, full stop, and underscore after the first letter. There are several different schools of thought about which is the best way to denote variables. In the past, I would have probably chosen a notation such as my.variable to indicate a variable, but after having coded for a long time alongside the magnificent data scientists and software engineers at Posit (former RStudio), I am now more used to a notation like my_variable which I do recommend.\n\n\nWe can work with variables joining them together with the usual operations. For example:\n\nbank_account &lt;- 100\ndeposit &lt;-  30\n\nbank_account &lt;- bank_account + deposit\n\nbank_account\n\n[1] 130\n\n\n\n\n\nR is a statistical software and in statistics a variable scarcely has only one value, but it is generally given as a list of values (measures). For example, one could have a variable age of the ages of all the employees of a small business. To store this in R, we can use the command c which stands for concatenate. For example\n\nages &lt;- c(25, 33, 45, 37, 28, 23, 42, 58, 29)\n\nNow the variable age is a vector. Let’s find out the length of this vector.\n\nlength(ages)\n\n[1] 9\n\n\nWe may also want to find out the average age of the employees of the business. This can be done with the command mean. E.g.\n\nmean(ages)\n\n[1] 35.55556\n\n\nOther statistical operations are median to calculate the median, IQR to find the interquartile range, sd to find the standard deviation and summary to show a five number summary of the variable, i.e. the minimum, lower quartile, median, upper quartile and maximum in the vector. The function summary also shows the mean.\n\nsummary(ages)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.00   28.00   33.00   35.56   42.00   58.00 \n\n\nIt is interesting to immediately notice that R functions may give different outcomes depending on the type of the variable. We shall come back to the type of a variable, but for the moment let’s just say that we consider an employee to be a junior employee if their age is below 33 years. To check whether the ages are below 33 we can use the normal order operations &lt; and &gt;.\n\nis_junior &lt;- ages &lt;= 33\nis_junior\n\n[1]  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\n\nIf we now run the summary command on the variable is_junior we no longer get a five number summary because the variable is_junior is not numeric.\n\nsummary(is_junior)\n\n   Mode   FALSE    TRUE \nlogical       4       5"
  },
  {
    "objectID": "r-basics.html#arithmetic-with-r",
    "href": "r-basics.html#arithmetic-with-r",
    "title": "Introduction to R",
    "section": "",
    "text": "In first instance, R is a very powerful and fancy calculator. Typing in the command line numerical expressions with the usual mathematical operations, we get the results we expect:\n\n2 + 3\n\n[1] 5\n\n\nThe four operations in R are +, -, * and / and R follows the usual mathematical rules for the priority of the operations (the one that some people call BIDMAS).\n\n5 * 2 - 12 / 4\n\n[1] 7\n\n\nThe order of the operations can be altered using brackets, like so:\n\n(4 + 5 * 2) / (8 / 2 - 3)\n\n[1] 14\n\n\nBesides the four operations, R has some very useful other operations, such as the integer division %/% and the modulo %% of two numbers. The integer division gives the quotient of the division and the modulo gives the remainder of the division, like so:\n\n25 %/% 4\n\n[1] 6\n\n\n\n25 %% 4\n\n[1] 1\n\n\nIn fact, we have 25 = 6 x 4 + 1.\nWe can also perform powers with R. The syntax is a ^ n to produce a to the power of n. For example,\n\n3 ^ 4\n\n[1] 81\n\n\n\n\nR is also equipped with two special “values” that represent “true” and “false”. These are called the Boolean values and denoted in R by TRUE or T, and FALSE or F. These two special values can be joined together through the logical operations which are: and, or, and not. In R, and is represented by &, or by | and not by !. So, for example, we have:\n\nTRUE & FALSE\n\n[1] FALSE\n\nTRUE | FALSE\n\n[1] TRUE\n\n!FALSE\n\n[1] TRUE\n\n\nAgain, logical values can be linked together with brackets."
  },
  {
    "objectID": "r-basics.html#variables-and-assignment",
    "href": "r-basics.html#variables-and-assignment",
    "title": "Introduction to R",
    "section": "",
    "text": "Once started understanding how R works with operations and numbers, we wish to start assigning values to variables and working with variables instead. R provides a special command to assign a value to a variable: &lt;-. This is called the assignment operator. For example\n\nx &lt;- 10\ny &lt;- 2.5\n\nx * y\n\n[1] 25\n\n\nYou don’t have to use a single letter to name a variable. Conversely, it is advisable not to do so, but to use meaningful words that recall the meaning of that variable. For example, to record the height and weight of an individual, we could use\n\nheight &lt;- 150\nweight &lt;- 65\n\n\n\n\n\n\n\nOn the names of variables\n\n\n\nA variable name must start with a letter, but it can contain also numbers, full stop, and underscore after the first letter. There are several different schools of thought about which is the best way to denote variables. In the past, I would have probably chosen a notation such as my.variable to indicate a variable, but after having coded for a long time alongside the magnificent data scientists and software engineers at Posit (former RStudio), I am now more used to a notation like my_variable which I do recommend.\n\n\nWe can work with variables joining them together with the usual operations. For example:\n\nbank_account &lt;- 100\ndeposit &lt;-  30\n\nbank_account &lt;- bank_account + deposit\n\nbank_account\n\n[1] 130"
  },
  {
    "objectID": "r-basics.html#r-data-types",
    "href": "r-basics.html#r-data-types",
    "title": "Introduction to R",
    "section": "",
    "text": "Unlike programming languages such as C, Pascal, etc, R doesn’t require to state in advance the type of the variables but it assigns the data type automatically. In most simple cases, the user doesn’t really need bother about the data types, but in some cases, and especially when one starts working with data frames and working in machine learning, awareness of the variable type is very important, and the ability to change data type is paramount.\nR has many different data types. In what follows we shall go through the most important of them.\n\n\nThe most common data type is double, i.e. decimal numbers described using floating point values. Any number is stored in R as a double, unless otherwise specified. So, for example, the following are double.\n\na &lt;- 5\nb &lt;- 2.2\n\nTo see the type of these variable, we can use the command typeof. So\n\ntypeof(a)\n\n[1] \"double\"\n\ntypeof(b)\n\n[1] \"double\"\n\n\n\n\n\nTo tell R that we want the number to be an integer we need to add an L after the number during the assignment. For example\n\nn &lt;- 5L\n\nis an integer. To see this, let’s use again the typeof command:\n\ntypeof(n)\n\n[1] \"integer\"\n\n\nDouble and integer are referred to as numeric variables.\n\n\n\nR has also the possibility to store complex numbers. This is done using the key i for the imaginary unit. For example:\n\nz &lt;- 2 + 3i\nw &lt;- 5 + 2i\n\nIf variables are complex, R knows how to adapt the arithmetic operations to complex numbers. For example,\n\nz + w\n\n[1] 7+5i\n\n2 * z\n\n[1] 4+6i\n\n(1 - 2i) * w\n\n[1] 9-8i\n\n\n\n\n\nAs we have mentioned before, R has two Boolean values (true and false). Their type is logical.\n\np &lt;- TRUE\ntypeof(p)\n\n[1] \"logical\"\n\n\n\n\n\nAnother common type is character, which is the data type of characters and strings. To assign a character type to a variable, we use the quotation marks: both the single ' and the double \" quotation marks work.\n\nchar &lt;- \"Hello, world!\"\ntypeof(char)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBeside typeof, there is another command that shows the type of a variable: class."
  },
  {
    "objectID": "r-basics.html#comparison-operators",
    "href": "r-basics.html#comparison-operators",
    "title": "Introduction to R",
    "section": "",
    "text": "In R we can use comparison operators to compare variables and return a logical value. The comparison operators are\n\n\n\nOperator\nName\nSyntax\n\n\n\n\n==\nequal\na == b\n\n\n!=\ndifferent\na != b\n\n\n&lt;=\nsmaller than, or equal to\na &lt;= b\n\n\n&lt;\nsmaller than\na &lt; b\n\n\n&gt;=\ngreater than, or equal to\na &gt;= b\n\n\n&gt;\ngreater than\na &gt; b\n\n\n\nFor example,\n\n5 &gt; 3\n\n[1] TRUE\n\n6 &lt; 3\n\n[1] FALSE"
  },
  {
    "objectID": "vectors.html",
    "href": "vectors.html",
    "title": "Vectors",
    "section": "",
    "text": "R is a statistical software and in statistics a variable scarcely has only one value, but it is generally given as a list of values (measurements). For example, one could have a variable ages of the ages of all the employees of a small business. To store this in R, we can use the function c() which stands for concatenate. To use this function, we pass the values of the vector as a list, separated by a comma. For example\n\nages &lt;- c(25, 33, 45, 37, 28, 23, 42, 58, 29)\nages\n\n[1] 25 33 45 37 28 23 42 58 29\n\n\nNow the variable ages is a vector. Let’s find out the length of this vector.\n\nlength(ages)\n\n[1] 9\n\n\n\n\nWe can create vectors with any data type. For example,\n\nnvec &lt;- c(1, 2, 3, 4, 5)\ntypeof(nvec)\n\n[1] \"double\"\n\ncvec &lt;- c(\"G\", \"C\", \"S\", \"E\")\ntypeof(cvec)\n\n[1] \"character\"\n\nlvec &lt;- c(TRUE, FALSE)\ntypeof(lvec)\n\n[1] \"logical\"\n\n\nIt is important to note now that all the elements of a vector must all have the same type. In fact, if we attempt to mix data types in a vector, R will convert them to force them to have all the same data type. For example,\n\nv &lt;- c(FALSE, 3, TRUE, 6)\ntypeof(v)\n\n[1] \"double\"\n\n\nIn fact, R will convert TRUE as 1 and FALSE as 0.\n\nw &lt;- c(\"A\", 1)\ntypeof(w)\n\n[1] \"character\"\n\n\nIn this case, as we could imagine, R converts everything to be a character.\n\nw\n\n[1] \"A\" \"1\"\n\n\n\n\n\nAn interesting feature of R is that each element in a vector can be named. Precisely, we can use the function name() to assign to each element of a vector a name. For example, imagine the following vector contains a week of temperatures:\n\ntemp &lt;- c(18, 16, 17, 17, 18, 16, 15)\ntemp\n\n[1] 18 16 17 17 18 16 15\n\n\nWe know that we have 7 temperatures for the 7 days of the week, but which temperature corresponds to which day? Does it start from Monday or from Sunday, or another day of the week? This is where the function name() can be used to assign a label to each value of the vector temp, as follows:\n\ndays &lt;- c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\nnames(temp) &lt;- days\ntemp\n\nMon Tue Wed Thu Fri Sat Sun \n 18  16  17  17  18  16  15 \n\n\n\n\n\n\nAs we have mentioned a couple of times already, R is a statistical software. This means that all aspects of R are centred on working with statistical data. Therefore, performing operations in R is specifically designed to make working with data as simple as possible. In particular, all arithmetic operations are vectorised, which means that the operations occur on an element by element basis. for example, take the following two vectors:\n\nvec_1 &lt;- c(1, 2, 3)\nvec_2 &lt;- c(5, 6, 7)\n\nAdding vectors:\n\nvec_1 + vec_2\n\n[1]  6  8 10\n\n\nSubtracting vectors:\n\nvec_1 - vec_2\n\n[1] -4 -4 -4\n\n\nMultiplying vectors:\n\nvec_1 * vec_2\n\n[1]  5 12 21\n\n\nDividing vectors:\n\nvec_1 / vec_2\n\n[1] 0.2000000 0.3333333 0.4285714\n\n\n\n\nWe can apply comparison operations of a single number to an entire vector. R will apply the comparison to every element of the vector, like so:\n\nvec &lt;- c(1, 2, 3, 4, 5, 6)\nvec &lt; 3.5\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE FALSE\n\nvec == 2\n\n[1] FALSE  TRUE FALSE FALSE FALSE FALSE\n\n\n\n\n\nLet’s come back to the example of the age of the employees of a business, ages. Imagine we wish to find the mean of the ages. To do so, we can use the function mean(), like so:\nmean(ages)\nSimilarly, we could find the median, the standard deviation, the interquartile range (IQR), etc, with similar functions. The following table contains some of the most common mathematical functions in R. A more comprehensive list of functions can be find in the R Reference Card published on CRAN.\n\n\n\n\n\n\n\nFunction\nMeaning\n\n\n\n\nsum(x)\nsum of the elements of x\n\n\nmin(x)\nminimum of the elements of x\n\n\nmax(x)\nmaximum of the elements of x\n\n\nmean(x)\nmean of the elements of x\n\n\nmedian(x)\nmedian of the elements of x\n\n\nquantile(x, probs)\nsample quantiles corresponding to the given probabilities (defaults to 0, 0.25, 0.5, 0.75, 1)\n\n\nvar(x)\nvariance of the elements of x (calculated on n-1)\n\n\nsd(x)\nstandard deviation of x (square root of the variance)\n\n\nIQR(x)\ninterquartile range of x\n\n\nlog(x, base)\ncomputes the logarithm of x with base base (default e, the natural logarithm)\n\n\n\nAnother very nice function is summary() which returns a summary statistics of the vector, i.e. the minimum, lower quartile, median, mean, upper quartile and maximum of the vector. For example,\n\nsummary(ages)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.00   28.00   33.00   35.56   42.00   58.00 \n\n\nIt is interesting to notice that R functions may give different outcomes depending on the type of the variable. We shall come back to the type of a variable, but for the moment let’s just say that we consider an employee to be a junior employee if their age is below 33 years. To check whether the ages are below 33 we can use the comparison operators, like so:\n\nis_junior &lt;- ages &lt;= 33\nis_junior\n\n[1]  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\n\nIf we now run the summary command on the variable is_junior we no longer get a five number summary because the variable is_junior is not numeric.\n\nsummary(is_junior)\n\n   Mode   FALSE    TRUE \nlogical       4       5 \n\n\n\n\n\n\nIt is sometimes important to be able to access a particular element of a given vector. For example, consider the following vector:\n\nvec &lt;- c(5, 10, 15, 20, 25, 30, 35, 40)\n\nWe can use the square brackets [ ] to access the individual elements of the vector. This can be done by indexing. In its simplest form, indexing works by using the brackets to pass the index position corresponding to the element as a number. Keep in mind that, unlike python, in R the index position starts at 1. So, for example,\n\nvec[3]\n\n[1] 15\n\n\nSometimes, however, we wish to access multiple elements at the same time. This can be done passing a vector of indices inside the square brackets; like so:\n\nvec[c(2, 3, 5)]\n\n[1] 10 15 25\n\n\nIf we pass a negative index to the vector, R will instead return the vector with all but the index passed. For example,\n\nvec[-3]\n\n[1]  5 10 20 25 30 35 40\n\n\n\n\nWe can also use the colon (:) to indicate a slice of vector. The colon operator from:to creates a vector of numbers that starts from from and ends at to, increasing by 1 unit every time. So, for example,\n\n3:7\n\n[1] 3 4 5 6 7\n\n\nNotice that if decimal numbers are given, it is possible that the second number is not necessarily part of the list, because the sequence terminates with the bigger number smaller than to, like so:\n\n3.5:7.2\n\n[1] 3.5 4.5 5.5 6.5\n\n\nSo, using the colon, we can get a slice of a vector, using the following syntax:\nvector[start_index:stop_index]\nFor example,\n\nvec[2:4]\n\n[1] 10 15 20\n\n\nNotice how the elements both at the starting and stopping index are included.\n\n\n\nWe have previously seen that we can assign names to the elements of a vector. For example,\n\nvec &lt;- c(5, 10, 15, 20, 25)\nnames(vec) &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nvec\n\n a  b  c  d  e \n 5 10 15 20 25 \n\n\nWe can then use the name along with the indexing brackets to grab the individual elements from the vector.\n\nvec[\"c\"]\n\n c \n15 \n\n\nAgain, we can also pass a vector of names to grab more than one vector at the same time.\n\nvec[c(\"a\", \"c\", \"e\")]\n\n a  c  e \n 5 15 25 \n\n\n\n\n\nAs we have mentioned before, talking about the comparison operators with vectors, we can use comparison operators to filter out elements from a vector. Sometimes this is referred to as boolean/logical masking, because we are creating a vector of logicals to filter out results you want.\nLet’s see an example of this. Take the vector\n\nvec &lt;- 1:10\nvec\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWe can pass to the brackets a logical statement.\n\nvec[vec &gt; 6]\n\n[1]  7  8  9 10\n\n\nLet’s break this down to see how it works. First, let’s have a look at the vector\n\nvec &gt; 6\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nAs we can see, it returns a logical vector with the same length as vec whose elements says whether it is true or false that the element in that position is greater than 6. When we pass a logical vector, such as this, to another vector through the brackets, R will return only the elements of the vector corresponding to a true value in the logical vector.\nTo make this more clear, we could even assign a name to this logical vector and pass the name to the vector, like so:\n\nfilter &lt;- vec &gt; 6\nfilter\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\nvec[filter]\n\n[1]  7  8  9 10\n\n\n\n\n\n\nBesides the function c() we have already seen that the colon operator from:to generates a sequence starting at from and ending at to. Another function that does the same job is seq(from, to, by = ). The parameter by specifies the increment of the sequence and its default value is 1. So, for example,\n\nseq(5, 16, by = 2)\n\n[1]  5  7  9 11 13 15\n\n\nAnother function that creates a vector is rep(x, times) which repeats the vector x times times.\n\nrep(c(1, 2), times = 3)\n\n[1] 1 2 1 2 1 2\n\n\nThe function rep has an alternative parameter each which repeats ‘each’ element of x each times. For example,\n\nrep(c(1, 2), each = 3)\n\n[1] 1 1 1 2 2 2\n\n\n\n\n\nSometimes instead of generating data with a pattern, we would like to simulate data. R is perfect for this job, as it has a very good implementation of all the most common and important statistical distributions needed. However, before we can simulate data, it is vital to say a few words about random data generation and reproducibility.\n\n\nAccording to Wikipedia, random number generation is a process by which, often by means of a random number generator (RGN), a sequence of numbers or symbols that cannot be reasonably predicted better than by random chance is generated. True random number generators are generally hardware based (for example by rolling a die). Software typically use a pseudo-random number generator (PRNG) which is an algorithm that generates a sequence of numbers that only looks random but that is in fact pre-determined. On Wikipedia there is long list of PRNGs, but for our scope, suffices it to say that the numbers that can be generated by R are in actual facts not random, but they would pass a random test, which means that they would look random from a mathematical point of view. If you want to know more about how R generates random numbers, you may wish to type help(\"RNG\") on your console.\n\n\n\nThis may look like a disadvantage, but it is actually a very important aspect of simulation. By means of the fact that random numbers are not-random after all, this means that if we “set a seed” we can then reproduce the exact random sequence again. This means that different user can perform the same simulation, obtaining the same result, as long as they use the same PRNG and they set the same seed.\nIn R the command to set the PRNG seed is set.seed().\nThis function needs to be assigned a number, the seed, which starts the sequence.\n\n\n\nLet’s see an example. Imagine we wish to roll a die. This means that we have a set of six possible outcomes (coded as 1 to 6), and by rolling a fair die we select one of them and all of them have the same probability (1 out of 6) to be selected. This can be done easily by sampling the set 1 to 6, i.e.\n\nset.seed(123)\nsample(1:6, 1)\n\n[1] 3\n\n\nImagine now we want to roll our die 10 times. This can be simulated using a similar code: we need to sample 10 times the set 1 to 6, but this sample must be with replacement. Thus we need to add the parameter replace = TRUE to the code to ensure that R samples with replacement. Let’s also set the same seed.\n\nset.seed(123)\nsample(1:6, 10, replace = TRUE)\n\n [1] 3 6 3 2 2 6 3 5 4 6\n\n\nWe may notice that having set the same seed, the first number is exactly the same as before.\n\n\n\n\n\n\nCaution\n\n\n\nA note of caution here: it is a good practice to set the seed every time we use a random generator function. In fact, once the seed has been set, the random function will use the PRGN in a specific way and different versions of the same function might use the PRNG in different ways. So once we access the PRNG again, it is good to always maintain control by choosing the seed, to ensure reproducibility.\n\n\n\n\n\nSuppose now we want to simulate a measurement (e.g. the temperature of a town). In this case we can’t sample from a population, but we need to use a statistical distribution. The statistical distribution that models a measurement is called the normal distribution and it has two parameters: the mean and the standard deviation. The mean represents the typical value of this measurement, and the standard deviation represent an approximation of the error made in taking this measurement.\nSo let’s run a simulation of 10 measurements of an average temperature of 18 degrees with a variability of 3 degrees.\n\nset.seed(101)\nrnorm(10, mean = 18, sd = 3)\n\n [1] 17.02189 19.65739 15.97517 18.64308 18.93231 21.52190 19.85637 17.66180\n [9] 20.75108 17.33022\n\n\nThis is way too accurate: let’s just round this to integers.\n\nset.seed(101)\nround(rnorm(10, mean = 18, sd = 3))\n\n [1] 17 20 16 19 19 22 20 18 21 17\n\n\nAnother very common distribution is the so called uniform distribution which gives the same probability to all numbers between a minimum and a maximum chosen numbers (defaults are min = 0 and max = 1). Let’s simulate 100 values from a uniform distribution:\n\nset.seed(111)\nrunif(100)\n\n  [1] 0.5929812845 0.7264811215 0.3704220036 0.5149238301 0.3776632159\n  [6] 0.4183373258 0.0106578451 0.5322952422 0.4321606164 0.0936815199\n [11] 0.5557799137 0.5902284889 0.0671411434 0.0475478533 0.1562025158\n [16] 0.4464277634 0.1714436871 0.9665342933 0.3106664298 0.6144663957\n [21] 0.4310607871 0.2855270915 0.3421513471 0.3866276275 0.9675274789\n [26] 0.3220267275 0.6532294548 0.2833034997 0.7874279192 0.5959206352\n [31] 0.0585964625 0.5098998600 0.4657924296 0.4693590938 0.3597453721\n [36] 0.7134103531 0.1163154817 0.7839926207 0.6421407105 0.8051009134\n [41] 0.6411978584 0.3284916454 0.6356909545 0.9285191579 0.5752422044\n [46] 0.3666838536 0.4366072204 0.8559219379 0.6279955737 0.7937756432\n [51] 0.7251648332 0.5850447209 0.0327716474 0.3329946804 0.9967166614\n [56] 0.5482733699 0.5758329388 0.4563152066 0.0965785654 0.8055401752\n [61] 0.0009253006 0.4667440471 0.1732608730 0.2592225648 0.9192820815\n [66] 0.2319295844 0.0525656715 0.3043926249 0.0117258150 0.3007076983\n [71] 0.8775839461 0.6652787277 0.4537648347 0.0533223320 0.6309068091\n [76] 0.4421851884 0.2673464869 0.9837744189 0.0951241532 0.7859691235\n [81] 0.1198521818 0.8812154671 0.1310980669 0.4003378763 0.0866140136\n [86] 0.3747997992 0.6847860171 0.7347726757 0.7709477365 0.5799853499\n [91] 0.5110989846 0.8529837073 0.6298211562 0.5790059080 0.7402492894\n [96] 0.3871497631 0.9935344572 0.3980894811 0.9750010339 0.8244822009\n\n\nThe table below shows the most common distributions with their syntax and a brief explanation.\n\n\n\n\n\n\n\n\nName\nSynatx\nExample of usage\n\n\n\n\nNormal distribution\nrnorm(n, mean = 0, sd = 1)\nThe normal distribution models measurements with mean mean and error sd\n\n\nUniform distribution\nrunif(n, min = 0, max = 1)\nThe uniform distribution is generally used to generate a sequence of random numbers\n\n\nBinomial distribution\nrbinom(n, size, prob)\nThe binomial distribution models the number of successes in size trials with probability of success prob\n\n\nPoisson distribution\nrpois(n, lambda)\nThe Poisson distribution is also called the “count” distribution: it models the number of events occurring at a constant rate in a given time frame. lambda is the mean number of events occurring.\n\n\nExponential distribution\nrexp(n, rate = 1)\nThe exponential distribution models the time to wait until the next event occurs, such as a failure or a success. rate is the average rate at which the events occur.\n\n\nGeometric distribution\nrgeom(n, prob)\nThe geometric distribution models the instant of first success in a sequence of trials with probability of success prob"
  },
  {
    "objectID": "vectors.html#vector-basics",
    "href": "vectors.html#vector-basics",
    "title": "Vectors",
    "section": "",
    "text": "R is a statistical software and in statistics a variable scarcely has only one value, but it is generally given as a list of values (measurements). For example, one could have a variable ages of the ages of all the employees of a small business. To store this in R, we can use the function c() which stands for concatenate. To use this function, we pass the values of the vector as a list, separated by a comma. For example\n\nages &lt;- c(25, 33, 45, 37, 28, 23, 42, 58, 29)\nages\n\n[1] 25 33 45 37 28 23 42 58 29\n\n\nNow the variable ages is a vector. Let’s find out the length of this vector.\n\nlength(ages)\n\n[1] 9\n\n\n\n\nWe can create vectors with any data type. For example,\n\nnvec &lt;- c(1, 2, 3, 4, 5)\ntypeof(nvec)\n\n[1] \"double\"\n\ncvec &lt;- c(\"G\", \"C\", \"S\", \"E\")\ntypeof(cvec)\n\n[1] \"character\"\n\nlvec &lt;- c(TRUE, FALSE)\ntypeof(lvec)\n\n[1] \"logical\"\n\n\nIt is important to note now that all the elements of a vector must all have the same type. In fact, if we attempt to mix data types in a vector, R will convert them to force them to have all the same data type. For example,\n\nv &lt;- c(FALSE, 3, TRUE, 6)\ntypeof(v)\n\n[1] \"double\"\n\n\nIn fact, R will convert TRUE as 1 and FALSE as 0.\n\nw &lt;- c(\"A\", 1)\ntypeof(w)\n\n[1] \"character\"\n\n\nIn this case, as we could imagine, R converts everything to be a character.\n\nw\n\n[1] \"A\" \"1\"\n\n\n\n\n\nAn interesting feature of R is that each element in a vector can be named. Precisely, we can use the function name() to assign to each element of a vector a name. For example, imagine the following vector contains a week of temperatures:\n\ntemp &lt;- c(18, 16, 17, 17, 18, 16, 15)\ntemp\n\n[1] 18 16 17 17 18 16 15\n\n\nWe know that we have 7 temperatures for the 7 days of the week, but which temperature corresponds to which day? Does it start from Monday or from Sunday, or another day of the week? This is where the function name() can be used to assign a label to each value of the vector temp, as follows:\n\ndays &lt;- c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\nnames(temp) &lt;- days\ntemp\n\nMon Tue Wed Thu Fri Sat Sun \n 18  16  17  17  18  16  15"
  },
  {
    "objectID": "vectors.html#operations-with-vectors",
    "href": "vectors.html#operations-with-vectors",
    "title": "Vectors",
    "section": "",
    "text": "As we have mentioned a couple of times already, R is a statistical software. This means that all aspects of R are centred on working with statistical data. Therefore, performing operations in R is specifically designed to make working with data as simple as possible. In particular, all arithmetic operations are vectorised, which means that the operations occur on an element by element basis. for example, take the following two vectors:\n\nvec_1 &lt;- c(1, 2, 3)\nvec_2 &lt;- c(5, 6, 7)\n\nAdding vectors:\n\nvec_1 + vec_2\n\n[1]  6  8 10\n\n\nSubtracting vectors:\n\nvec_1 - vec_2\n\n[1] -4 -4 -4\n\n\nMultiplying vectors:\n\nvec_1 * vec_2\n\n[1]  5 12 21\n\n\nDividing vectors:\n\nvec_1 / vec_2\n\n[1] 0.2000000 0.3333333 0.4285714\n\n\n\n\nWe can apply comparison operations of a single number to an entire vector. R will apply the comparison to every element of the vector, like so:\n\nvec &lt;- c(1, 2, 3, 4, 5, 6)\nvec &lt; 3.5\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE FALSE\n\nvec == 2\n\n[1] FALSE  TRUE FALSE FALSE FALSE FALSE\n\n\n\n\n\nLet’s come back to the example of the age of the employees of a business, ages. Imagine we wish to find the mean of the ages. To do so, we can use the function mean(), like so:\nmean(ages)\nSimilarly, we could find the median, the standard deviation, the interquartile range (IQR), etc, with similar functions. The following table contains some of the most common mathematical functions in R. A more comprehensive list of functions can be find in the R Reference Card published on CRAN.\n\n\n\n\n\n\n\nFunction\nMeaning\n\n\n\n\nsum(x)\nsum of the elements of x\n\n\nmin(x)\nminimum of the elements of x\n\n\nmax(x)\nmaximum of the elements of x\n\n\nmean(x)\nmean of the elements of x\n\n\nmedian(x)\nmedian of the elements of x\n\n\nquantile(x, probs)\nsample quantiles corresponding to the given probabilities (defaults to 0, 0.25, 0.5, 0.75, 1)\n\n\nvar(x)\nvariance of the elements of x (calculated on n-1)\n\n\nsd(x)\nstandard deviation of x (square root of the variance)\n\n\nIQR(x)\ninterquartile range of x\n\n\nlog(x, base)\ncomputes the logarithm of x with base base (default e, the natural logarithm)\n\n\n\nAnother very nice function is summary() which returns a summary statistics of the vector, i.e. the minimum, lower quartile, median, mean, upper quartile and maximum of the vector. For example,\n\nsummary(ages)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.00   28.00   33.00   35.56   42.00   58.00 \n\n\nIt is interesting to notice that R functions may give different outcomes depending on the type of the variable. We shall come back to the type of a variable, but for the moment let’s just say that we consider an employee to be a junior employee if their age is below 33 years. To check whether the ages are below 33 we can use the comparison operators, like so:\n\nis_junior &lt;- ages &lt;= 33\nis_junior\n\n[1]  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE\n\n\nIf we now run the summary command on the variable is_junior we no longer get a five number summary because the variable is_junior is not numeric.\n\nsummary(is_junior)\n\n   Mode   FALSE    TRUE \nlogical       4       5"
  },
  {
    "objectID": "r-basics.html#getting-help-with-r",
    "href": "r-basics.html#getting-help-with-r",
    "title": "Introduction to R",
    "section": "",
    "text": "Besides google searching and visiting Stack Overflow, there are some build-in functions to get help from R. In fact, most of the R functions have documentation and examples. To access the documentation of a function foo we can either use ?foo or help(foo). For example,\n\nhelp(vector)\n\nopens the documentation with title Vectors - Creation, Coercion, etc."
  },
  {
    "objectID": "vectors.html#vector-indexing-and-slicing",
    "href": "vectors.html#vector-indexing-and-slicing",
    "title": "Vectors",
    "section": "",
    "text": "It is sometimes important to be able to access a particular element of a given vector. For example, consider the following vector:\n\nvec &lt;- c(5, 10, 15, 20, 25, 30, 35, 40)\n\nWe can use the square brackets [ ] to access the individual elements of the vector. This can be done by indexing. In its simplest form, indexing works by using the brackets to pass the index position corresponding to the element as a number. Keep in mind that, unlike python, in R the index position starts at 1. So, for example,\n\nvec[3]\n\n[1] 15\n\n\nSometimes, however, we wish to access multiple elements at the same time. This can be done passing a vector of indices inside the square brackets; like so:\n\nvec[c(2, 3, 5)]\n\n[1] 10 15 25\n\n\nIf we pass a negative index to the vector, R will instead return the vector with all but the index passed. For example,\n\nvec[-3]\n\n[1]  5 10 20 25 30 35 40\n\n\n\n\nWe can also use the colon (:) to indicate a slice of vector. The colon operator from:to creates a vector of numbers that starts from from and ends at to, increasing by 1 unit every time. So, for example,\n\n3:7\n\n[1] 3 4 5 6 7\n\n\nNotice that if decimal numbers are given, it is possible that the second number is not necessarily part of the list, because the sequence terminates with the bigger number smaller than to, like so:\n\n3.5:7.2\n\n[1] 3.5 4.5 5.5 6.5\n\n\nSo, using the colon, we can get a slice of a vector, using the following syntax:\nvector[start_index:stop_index]\nFor example,\n\nvec[2:4]\n\n[1] 10 15 20\n\n\nNotice how the elements both at the starting and stopping index are included.\n\n\n\nWe have previously seen that we can assign names to the elements of a vector. For example,\n\nvec &lt;- c(5, 10, 15, 20, 25)\nnames(vec) &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nvec\n\n a  b  c  d  e \n 5 10 15 20 25 \n\n\nWe can then use the name along with the indexing brackets to grab the individual elements from the vector.\n\nvec[\"c\"]\n\n c \n15 \n\n\nAgain, we can also pass a vector of names to grab more than one vector at the same time.\n\nvec[c(\"a\", \"c\", \"e\")]\n\n a  c  e \n 5 15 25 \n\n\n\n\n\nAs we have mentioned before, talking about the comparison operators with vectors, we can use comparison operators to filter out elements from a vector. Sometimes this is referred to as boolean/logical masking, because we are creating a vector of logicals to filter out results you want.\nLet’s see an example of this. Take the vector\n\nvec &lt;- 1:10\nvec\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWe can pass to the brackets a logical statement.\n\nvec[vec &gt; 6]\n\n[1]  7  8  9 10\n\n\nLet’s break this down to see how it works. First, let’s have a look at the vector\n\nvec &gt; 6\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nAs we can see, it returns a logical vector with the same length as vec whose elements says whether it is true or false that the element in that position is greater than 6. When we pass a logical vector, such as this, to another vector through the brackets, R will return only the elements of the vector corresponding to a true value in the logical vector.\nTo make this more clear, we could even assign a name to this logical vector and pass the name to the vector, like so:\n\nfilter &lt;- vec &gt; 6\nfilter\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\nvec[filter]\n\n[1]  7  8  9 10"
  },
  {
    "objectID": "vectors.html#two-useful-functions-to-generate-vectors",
    "href": "vectors.html#two-useful-functions-to-generate-vectors",
    "title": "Vectors",
    "section": "",
    "text": "Besides the function c() we have already seen that the colon operator from:to generates a sequence starting at from and ending at to. Another function that does the same job is seq(from, to, by = ). The parameter by specifies the increment of the sequence and its default value is 1. So, for example,\n\nseq(5, 16, by = 2)\n\n[1]  5  7  9 11 13 15\n\n\nAnother function that creates a vector is rep(x, times) which repeats the vector x times times.\n\nrep(c(1, 2), times = 3)\n\n[1] 1 2 1 2 1 2\n\n\nThe function rep has an alternative parameter each which repeats ‘each’ element of x each times. For example,\n\nrep(c(1, 2), each = 3)\n\n[1] 1 1 1 2 2 2"
  },
  {
    "objectID": "vectors.html#first-step-in-data-simulation",
    "href": "vectors.html#first-step-in-data-simulation",
    "title": "Vectors",
    "section": "",
    "text": "Sometimes instead of generating data with a pattern, we would like to simulate data. R is perfect for this job, as it has a very good implementation of all the most common and important statistical distributions needed. However, before we can simulate data, it is vital to say a few words about random data generation and reproducibility.\n\n\nAccording to Wikipedia, random number generation is a process by which, often by means of a random number generator (RGN), a sequence of numbers or symbols that cannot be reasonably predicted better than by random chance is generated. True random number generators are generally hardware based (for example by rolling a die). Software typically use a pseudo-random number generator (PRNG) which is an algorithm that generates a sequence of numbers that only looks random but that is in fact pre-determined. On Wikipedia there is long list of PRNGs, but for our scope, suffices it to say that the numbers that can be generated by R are in actual facts not random, but they would pass a random test, which means that they would look random from a mathematical point of view. If you want to know more about how R generates random numbers, you may wish to type help(\"RNG\") on your console.\n\n\n\nThis may look like a disadvantage, but it is actually a very important aspect of simulation. By means of the fact that random numbers are not-random after all, this means that if we “set a seed” we can then reproduce the exact random sequence again. This means that different user can perform the same simulation, obtaining the same result, as long as they use the same PRNG and they set the same seed.\nIn R the command to set the PRNG seed is set.seed().\nThis function needs to be assigned a number, the seed, which starts the sequence.\n\n\n\nLet’s see an example. Imagine we wish to roll a die. This means that we have a set of six possible outcomes (coded as 1 to 6), and by rolling a fair die we select one of them and all of them have the same probability (1 out of 6) to be selected. This can be done easily by sampling the set 1 to 6, i.e.\n\nset.seed(123)\nsample(1:6, 1)\n\n[1] 3\n\n\nImagine now we want to roll our die 10 times. This can be simulated using a similar code: we need to sample 10 times the set 1 to 6, but this sample must be with replacement. Thus we need to add the parameter replace = TRUE to the code to ensure that R samples with replacement. Let’s also set the same seed.\n\nset.seed(123)\nsample(1:6, 10, replace = TRUE)\n\n [1] 3 6 3 2 2 6 3 5 4 6\n\n\nWe may notice that having set the same seed, the first number is exactly the same as before.\n\n\n\n\n\n\nCaution\n\n\n\nA note of caution here: it is a good practice to set the seed every time we use a random generator function. In fact, once the seed has been set, the random function will use the PRGN in a specific way and different versions of the same function might use the PRNG in different ways. So once we access the PRNG again, it is good to always maintain control by choosing the seed, to ensure reproducibility.\n\n\n\n\n\nSuppose now we want to simulate a measurement (e.g. the temperature of a town). In this case we can’t sample from a population, but we need to use a statistical distribution. The statistical distribution that models a measurement is called the normal distribution and it has two parameters: the mean and the standard deviation. The mean represents the typical value of this measurement, and the standard deviation represent an approximation of the error made in taking this measurement.\nSo let’s run a simulation of 10 measurements of an average temperature of 18 degrees with a variability of 3 degrees.\n\nset.seed(101)\nrnorm(10, mean = 18, sd = 3)\n\n [1] 17.02189 19.65739 15.97517 18.64308 18.93231 21.52190 19.85637 17.66180\n [9] 20.75108 17.33022\n\n\nThis is way too accurate: let’s just round this to integers.\n\nset.seed(101)\nround(rnorm(10, mean = 18, sd = 3))\n\n [1] 17 20 16 19 19 22 20 18 21 17\n\n\nAnother very common distribution is the so called uniform distribution which gives the same probability to all numbers between a minimum and a maximum chosen numbers (defaults are min = 0 and max = 1). Let’s simulate 100 values from a uniform distribution:\n\nset.seed(111)\nrunif(100)\n\n  [1] 0.5929812845 0.7264811215 0.3704220036 0.5149238301 0.3776632159\n  [6] 0.4183373258 0.0106578451 0.5322952422 0.4321606164 0.0936815199\n [11] 0.5557799137 0.5902284889 0.0671411434 0.0475478533 0.1562025158\n [16] 0.4464277634 0.1714436871 0.9665342933 0.3106664298 0.6144663957\n [21] 0.4310607871 0.2855270915 0.3421513471 0.3866276275 0.9675274789\n [26] 0.3220267275 0.6532294548 0.2833034997 0.7874279192 0.5959206352\n [31] 0.0585964625 0.5098998600 0.4657924296 0.4693590938 0.3597453721\n [36] 0.7134103531 0.1163154817 0.7839926207 0.6421407105 0.8051009134\n [41] 0.6411978584 0.3284916454 0.6356909545 0.9285191579 0.5752422044\n [46] 0.3666838536 0.4366072204 0.8559219379 0.6279955737 0.7937756432\n [51] 0.7251648332 0.5850447209 0.0327716474 0.3329946804 0.9967166614\n [56] 0.5482733699 0.5758329388 0.4563152066 0.0965785654 0.8055401752\n [61] 0.0009253006 0.4667440471 0.1732608730 0.2592225648 0.9192820815\n [66] 0.2319295844 0.0525656715 0.3043926249 0.0117258150 0.3007076983\n [71] 0.8775839461 0.6652787277 0.4537648347 0.0533223320 0.6309068091\n [76] 0.4421851884 0.2673464869 0.9837744189 0.0951241532 0.7859691235\n [81] 0.1198521818 0.8812154671 0.1310980669 0.4003378763 0.0866140136\n [86] 0.3747997992 0.6847860171 0.7347726757 0.7709477365 0.5799853499\n [91] 0.5110989846 0.8529837073 0.6298211562 0.5790059080 0.7402492894\n [96] 0.3871497631 0.9935344572 0.3980894811 0.9750010339 0.8244822009\n\n\nThe table below shows the most common distributions with their syntax and a brief explanation.\n\n\n\n\n\n\n\n\nName\nSynatx\nExample of usage\n\n\n\n\nNormal distribution\nrnorm(n, mean = 0, sd = 1)\nThe normal distribution models measurements with mean mean and error sd\n\n\nUniform distribution\nrunif(n, min = 0, max = 1)\nThe uniform distribution is generally used to generate a sequence of random numbers\n\n\nBinomial distribution\nrbinom(n, size, prob)\nThe binomial distribution models the number of successes in size trials with probability of success prob\n\n\nPoisson distribution\nrpois(n, lambda)\nThe Poisson distribution is also called the “count” distribution: it models the number of events occurring at a constant rate in a given time frame. lambda is the mean number of events occurring.\n\n\nExponential distribution\nrexp(n, rate = 1)\nThe exponential distribution models the time to wait until the next event occurs, such as a failure or a success. rate is the average rate at which the events occur.\n\n\nGeometric distribution\nrgeom(n, prob)\nThe geometric distribution models the instant of first success in a sequence of trials with probability of success prob"
  },
  {
    "objectID": "vectors.html#first-steps-in-data-simulation",
    "href": "vectors.html#first-steps-in-data-simulation",
    "title": "Vectors",
    "section": "",
    "text": "Sometimes instead of generating data with a pattern, we would like to simulate data. R is perfect for this job, as it has a very good implementation of all the most common and important statistical distributions needed. However, before we can simulate data, it is vital to say a few words about random data generation and reproducibility.\n\n\nAccording to Wikipedia, random number generation is a process by which, often by means of a random number generator (RGN), a sequence of numbers or symbols that cannot be reasonably predicted better than by random chance is generated. True random number generators are generally hardware based (for example by rolling a die). Software typically use a pseudo-random number generator (PRNG) which is an algorithm that generates a sequence of numbers that only looks random but that is in fact pre-determined. On Wikipedia there is long list of PRNGs, but for our scope, suffices it to say that the numbers that can be generated by R are in actual facts not random, but they would pass a random test, which means that they would look random from a mathematical point of view. If you want to know more about how R generates random numbers, you may wish to type help(\"RNG\") on your console.\n\n\n\nThis may look like a disadvantage, but it is actually a very important aspect of simulation. By means of the fact that random numbers are not-random after all, this means that if we “set a seed” we can then reproduce the exact random sequence again. This means that different user can perform the same simulation, obtaining the same result, as long as they use the same PRNG and they set the same seed.\nIn R the command to set the PRNG seed is set.seed().\nThis function needs to be assigned a number, the seed, which starts the sequence.\n\n\n\nLet’s see an example. Imagine we wish to roll a die. This means that we have a set of six possible outcomes (coded as 1 to 6), and by rolling a fair die we select one of them and all of them have the same probability (1 out of 6) to be selected. This can be done easily by sampling the set 1 to 6, i.e.\n\nset.seed(123)\nsample(1:6, 1)\n\n[1] 3\n\n\nImagine now we want to roll our die 10 times. This can be simulated using a similar code: we need to sample 10 times the set 1 to 6, but this sample must be with replacement. Thus we need to add the parameter replace = TRUE to the code to ensure that R samples with replacement. Let’s also set the same seed.\n\nset.seed(123)\nsample(1:6, 10, replace = TRUE)\n\n [1] 3 6 3 2 2 6 3 5 4 6\n\n\nWe may notice that having set the same seed, the first number is exactly the same as before.\n\n\n\n\n\n\nCaution\n\n\n\nA note of caution here: it is a good practice to set the seed every time we use a random generator function. In fact, once the seed has been set, the random function will use the PRGN in a specific way and different versions of the same function might use the PRNG in different ways. So once we access the PRNG again, it is good to always maintain control by choosing the seed, to ensure reproducibility.\n\n\n\n\n\nSuppose now we want to simulate a measurement (e.g. the temperature of a town). In this case we can’t sample from a population, but we need to use a statistical distribution. The statistical distribution that models a measurement is called the normal distribution and it has two parameters: the mean and the standard deviation. The mean represents the typical value of this measurement, and the standard deviation represent an approximation of the error made in taking this measurement.\nSo let’s run a simulation of 10 measurements of an average temperature of 18 degrees with a variability of 3 degrees.\n\nset.seed(101)\nrnorm(10, mean = 18, sd = 3)\n\n [1] 17.02189 19.65739 15.97517 18.64308 18.93231 21.52190 19.85637 17.66180\n [9] 20.75108 17.33022\n\n\nThis is way too accurate: let’s just round this to integers.\n\nset.seed(101)\nround(rnorm(10, mean = 18, sd = 3))\n\n [1] 17 20 16 19 19 22 20 18 21 17\n\n\nAnother very common distribution is the so called uniform distribution which gives the same probability to all numbers between a minimum and a maximum chosen numbers (defaults are min = 0 and max = 1). Let’s simulate 100 values from a uniform distribution:\n\nset.seed(111)\nrunif(100)\n\n  [1] 0.5929812845 0.7264811215 0.3704220036 0.5149238301 0.3776632159\n  [6] 0.4183373258 0.0106578451 0.5322952422 0.4321606164 0.0936815199\n [11] 0.5557799137 0.5902284889 0.0671411434 0.0475478533 0.1562025158\n [16] 0.4464277634 0.1714436871 0.9665342933 0.3106664298 0.6144663957\n [21] 0.4310607871 0.2855270915 0.3421513471 0.3866276275 0.9675274789\n [26] 0.3220267275 0.6532294548 0.2833034997 0.7874279192 0.5959206352\n [31] 0.0585964625 0.5098998600 0.4657924296 0.4693590938 0.3597453721\n [36] 0.7134103531 0.1163154817 0.7839926207 0.6421407105 0.8051009134\n [41] 0.6411978584 0.3284916454 0.6356909545 0.9285191579 0.5752422044\n [46] 0.3666838536 0.4366072204 0.8559219379 0.6279955737 0.7937756432\n [51] 0.7251648332 0.5850447209 0.0327716474 0.3329946804 0.9967166614\n [56] 0.5482733699 0.5758329388 0.4563152066 0.0965785654 0.8055401752\n [61] 0.0009253006 0.4667440471 0.1732608730 0.2592225648 0.9192820815\n [66] 0.2319295844 0.0525656715 0.3043926249 0.0117258150 0.3007076983\n [71] 0.8775839461 0.6652787277 0.4537648347 0.0533223320 0.6309068091\n [76] 0.4421851884 0.2673464869 0.9837744189 0.0951241532 0.7859691235\n [81] 0.1198521818 0.8812154671 0.1310980669 0.4003378763 0.0866140136\n [86] 0.3747997992 0.6847860171 0.7347726757 0.7709477365 0.5799853499\n [91] 0.5110989846 0.8529837073 0.6298211562 0.5790059080 0.7402492894\n [96] 0.3871497631 0.9935344572 0.3980894811 0.9750010339 0.8244822009\n\n\nThe table below shows the most common distributions with their syntax and a brief explanation.\n\n\n\n\n\n\n\n\nName\nSynatx\nExample of usage\n\n\n\n\nNormal distribution\nrnorm(n, mean = 0, sd = 1)\nThe normal distribution models measurements with mean mean and error sd\n\n\nUniform distribution\nrunif(n, min = 0, max = 1)\nThe uniform distribution is generally used to generate a sequence of random numbers\n\n\nBinomial distribution\nrbinom(n, size, prob)\nThe binomial distribution models the number of successes in size trials with probability of success prob\n\n\nPoisson distribution\nrpois(n, lambda)\nThe Poisson distribution is also called the “count” distribution: it models the number of events occurring at a constant rate in a given time frame. lambda is the mean number of events occurring.\n\n\nExponential distribution\nrexp(n, rate = 1)\nThe exponential distribution models the time to wait until the next event occurs, such as a failure or a success. rate is the average rate at which the events occur.\n\n\nGeometric distribution\nrgeom(n, prob)\nThe geometric distribution models the instant of first success in a sequence of trials with probability of success prob"
  },
  {
    "objectID": "data-frames.html",
    "href": "data-frames.html",
    "title": "Data Frames",
    "section": "",
    "text": "Data frames are used to store tabular data in R. They are an important type of object and are used in a variety of statistical modelling applications. The tidyverse meta-package has an enhanced version of data frame, called a tibble and an optimised set of functions designed to work effectively with data frames and tibbles.\nBefore we continue, it is therefore necessary to install, and load, the tidyverse.\n\n\nAnyone can create new R packages, but only when packages satisfy certain strict rules are stored on CRAN. This ensures that packages stores on CRAN are reliable, have documentation and there is a support in place for the users. To install a package that lives on CRAN it suffices to type on the console install.packages(\"package_name\"). R will then install the package and all the dependencies needed to run the package.\nSo, to install the whole tidyverse we just have to type install.packages(\"tidyverse\").\nTo load a package (regardless of where it comes from), we need to use the command library(). So, to load the tidyverse we can just type in out script and run the code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThe outcome is pretty overwhelming! First we are informed that all the core tidyverse packages are correctly loaded: dplyr, forecats, ggplot2, lubridate, purrr, readr, stringr, tibble and tidyr. Then we are also informed that there are two functions that were already loaded from the package stats (a core package automatically loaded by R), and they are now substituted by the homonym functions from dplyr. This might seem like a loss, but the stats functions are not lost, we only need to call them via their “long name”.\n\n\nThe long name of a function is composed by the name of the package where the function is stored, two colons (::) and the name of the function. So, to use the function filter() in stats we can type stats::filter(). Similarly, if we wanted to use the function read_csv() which lies in the package readr, we could just type readr::read_csv() without the needs to load the package readr in advance.\n\n\n\n\n\n\nTip\n\n\n\nIt is good practice to always load at the beginning of the script code the packages that are going to be used, even though, sometimes, we may end up using the long name for the sake of clarity, or to avoid conflicts between packages.\n\n\n\n\n\n\nQuoting from the tidyverse home page:\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\nAs we have seen by loading the tidyverse, this meta-package is composed of 9 packages, each with a specific function, to make the code more readable, effective and data analysis more enjoyable.\nThe first feature of the tidyverse that we want to get acquainted with is a tibble. Again, quoting from the tidyverse home page: “A tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what it has not. Tibbles are data.frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code.”\n\n\n\nTibbles are represented as a special type of bivariate data sets, where every column may store different type of objects, but the overall length of each column must be the same. Tibbles may be thought of as two-by-two matrices, where the rows represent different items, and each column represents the variables that are recorded, or measured, for each item. Thus tibbles are the object that correctly represents a data set.\nTibbles are generally created by reading in a data set using the readr functions such as read_csv() or read_delim(). However, tibbles can also be created explicitly using the tibble() function. For example,\n\ntibble(\n    name = c(\"Alice\", \"Bob\", \"Charlie\"),\n    age = c(25, 31, 36),\n    salary = c(14000, 18000, 25000)\n)\n\n# A tibble: 3 × 3\n  name      age salary\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Alice      25  14000\n2 Bob        31  18000\n3 Charlie    36  25000\n\n\nThis is easy however, only when the variables (name, age and salary are already stored in some vectors, and we wish to collate them together into a data frame). When we try to store them one by one, it is often more logical to give the data row by row. This can be done with a variant of tibble called tribble(), like so:\n\ntribble(\n    ~ name, ~ age, ~ salary,\n    \"Alice\", 25, 14000,\n    \"Bob\", 21, 18000,\n    \"Charlie\", 56, 25000\n)\n\n# A tibble: 3 × 3\n  name      age salary\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Alice      25  14000\n2 Bob        21  18000\n3 Charlie    56  25000\n\n\nNote the presence of the symbol ~ before the names of the columns (i.e. the names of the variables) when defined using the tribble() function.\nGenerally speaking, the tribble() function works well when one wishes to write down the data directly, while the tibble() function works well to collect into a tibble different variables already stored into single vectors. For example, assume we have recorded the height (in cm) and the weight (in kg) of a sample of students and we have stored this information into the variables height and weight, like so:\n\nheight &lt;- c(163, 171, 159, 162, 161, 174, 177, 158, 164, 177)\nweight &lt;- c(65, 78, 73, 81, 83, 79, 80, 76, 82, 88)\n\nThen we can collect these variables into a tibble, like so:\n\nstudents &lt;- tibble(height, weight)\nstudents\n\n# A tibble: 10 × 2\n   height weight\n    &lt;dbl&gt;  &lt;dbl&gt;\n 1    163     65\n 2    171     78\n 3    159     73\n 4    162     81\n 5    161     83\n 6    174     79\n 7    177     80\n 8    158     76\n 9    164     82\n10    177     88\n\n\nNevertheless, it should be quite evident that when the data set is big, this is not the best way to create a data set. Before exploring how to import data sets into R, however, it may be worth exploring a few data sets.\n\n\n\nR contains several examples of data sets, some of which particularly interesting because they are data sets of historical value, like the iris data set. To see which data sets are included in R, we can use the command data(). This opens a new tab in RStudio showing the list of data sets included in base R.\nAny of these data sets can be called simply typing their name on the console (or running the corresponding code in the R script). However, data sets stored in R cannot be changed, and in order to have the flexibility to make changes, we may wish to save a copy in the memory. However, since the base R saves data sets as data.frame type, we may wish to transform them into a tibble, with the command as_tibble(), like so:\n\niris &lt;- as_tibble(iris)\niris\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n\nNote that the data sets contains 150 rows, but one of the features of a tibble is that it shows only the first 10 rows. If we wish to see more (or less) rows, we can pass the tibble to the function print() and state the numbers of rows to print. For instance, to see the first three rows, we can use\n\nprint(iris, n = 3)\n\n# A tibble: 150 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n# ℹ 147 more rows\n\n\nIf we wish to see the structure of the variables of this data set, we can use the glimpse() function, which shows the list of the variables together with their type and the first few values of each of them. For example,\n\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nWe have also already established that the function summary() is adaptable and its outcome depends on the type of object that we pass to it. Let’s see what happens when we pass a tibble to this function.\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nNicely, summary() returns a summary of each variable in the tibble, and each summary depends on the type of the variable.\nAnother nice data set stored in R is airquality, which shows the Daily air quality measurements in New York, May to September 1973. To store it as a tibble, let’s run the following\n\nairquality &lt;- as_tibble(airquality)\nairquality\n\n# A tibble: 153 × 6\n   Ozone Solar.R  Wind  Temp Month   Day\n   &lt;int&gt;   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    41     190   7.4    67     5     1\n 2    36     118   8      72     5     2\n 3    12     149  12.6    74     5     3\n 4    18     313  11.5    62     5     4\n 5    NA      NA  14.3    56     5     5\n 6    28      NA  14.9    66     5     6\n 7    23     299   8.6    65     5     7\n 8    19      99  13.8    59     5     8\n 9     8      19  20.1    61     5     9\n10    NA     194   8.6    69     5    10\n# ℹ 143 more rows\n\n\nHere we can notice a feature that we have not seen before: the presence of NA’s into the data set. NA is a special type of logical value which stands for “Not Available”. This represents a missing value. It is often the case that a data set is incomplete, i.e. that some of the data is not recorded, or it is lost. If these situations are saved as NA, R can keep track of the missing value and handle it accordingly. There are several functions in R that help dealing with missing values.\nAnother example of data set comes from the package ggplot2 (one of the tidyverse core packages) and it is called mpg; it contains the Fuel economy data from 1999 to 2008 for 38 popular models of cars. This is a data set stored into the tidyverse so it is already a tibble. To see it we can just call it, like so:\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\nAn interesting fact about this data set is the variety of variables stored in it. Let’s have a proper look with glimpse():\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\nLet’s also use summary() to have a look at a summary of these values.\n\nsummary(mpg)\n\n manufacturer          model               displ            year     \n Length:234         Length:234         Min.   :1.600   Min.   :1999  \n Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999  \n Mode  :character   Mode  :character   Median :3.300   Median :2004  \n                                       Mean   :3.472   Mean   :2004  \n                                       3rd Qu.:4.600   3rd Qu.:2008  \n                                       Max.   :7.000   Max.   :2008  \n      cyl           trans               drv                 cty       \n Min.   :4.000   Length:234         Length:234         Min.   : 9.00  \n 1st Qu.:4.000   Class :character   Class :character   1st Qu.:14.00  \n Median :6.000   Mode  :character   Mode  :character   Median :17.00  \n Mean   :5.889                                         Mean   :16.86  \n 3rd Qu.:8.000                                         3rd Qu.:19.00  \n Max.   :8.000                                         Max.   :35.00  \n      hwy             fl               class          \n Min.   :12.00   Length:234         Length:234        \n 1st Qu.:18.00   Class :character   Class :character  \n Median :24.00   Mode  :character   Mode  :character  \n Mean   :23.44                                        \n 3rd Qu.:27.00                                        \n Max.   :44.00                                        \n\n\nA quick look shows that most of these summaries is little informative. For example, the number of cylinders, cyl, really not helpful to understand what is going on. Same for the model, which only tells us that there are 234 data, bat what is the distribution of the models?\nTo answer that, we need to explain R that some of these data are not just characters (or numbers), but they are “categorical data”, which R calls factors.\n\n\n\nFactors are categorical data, i.e. qualitative or non-numerical data. For instance, social class, primary diagnosis, tumor stage, Tanner stage of puberty, etc are all examples of categorical data. They are typically input using a numeric code, but they can also be stored as characters.\nSuch variables should always be specified as factor in R. This is the data structure that (among other things) makes it possible to assign meaningful names to the categories, instead of reading them as mere strings of characters (such as IDs).\nThe terminology is that a factor has a set of levels — say four levels for concreteness. Internally, a four-level factor consists of two items: (a) a vector of integers between 1 and 4, and (b) a character vector of length 4 containing strings describing what the four levels are. Let’s look at an example, before going back to the mpg data set.\n\npain &lt;- c(0, 3, 2, 2, 1)\nfpain &lt;- factor(pain, levels = 0:3)\nlevels(fpain) &lt;- c(\"none\", \"mild\", \"medium\", \"severe\")\n\npain\n\n[1] 0 3 2 2 1\n\nfpain\n\n[1] none   severe medium medium mild  \nLevels: none mild medium severe\n\n\nThe first command creates a numeric vector pain, encoding the pain levels of five patients. We wish to treat this as categorical variable, so we create a factor fpain from it using the function factor(). This is called with one argument in addition to pain, namely levels = 0:3, which indicates that the input coding uses the values 0 to 3. The latter can in principle be left out since R by default uses the values in pain, suitably sorted, but it is a good habit to retain it. The effect of the final line is that the level names are changed to the four specified character strings.\nNow let’s return to the mpg data set. We wish to convert the variable cyl to factor. To do so, let’s use some powerful features of the tidyverse, and in particular of the package dplyr. Precisely, we can “mutate” the variable cyl transforming it into a factor, using the function mutate(), like so:\n\nmpg &lt;- mutate(mpg, cyl = factor(cyl))\n\nWe can now see what happens calling the summary() again.\n\nsummary(mpg)\n\n manufacturer          model               displ            year      cyl   \n Length:234         Length:234         Min.   :1.600   Min.   :1999   4:81  \n Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999   5: 4  \n Mode  :character   Mode  :character   Median :3.300   Median :2004   6:79  \n                                       Mean   :3.472   Mean   :2004   8:70  \n                                       3rd Qu.:4.600   3rd Qu.:2008         \n                                       Max.   :7.000   Max.   :2008         \n    trans               drv                 cty             hwy       \n Length:234         Length:234         Min.   : 9.00   Min.   :12.00  \n Class :character   Class :character   1st Qu.:14.00   1st Qu.:18.00  \n Mode  :character   Mode  :character   Median :17.00   Median :24.00  \n                                       Mean   :16.86   Mean   :23.44  \n                                       3rd Qu.:19.00   3rd Qu.:27.00  \n                                       Max.   :35.00   Max.   :44.00  \n      fl               class          \n Length:234         Length:234        \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nNow, correctly, R recognises that the number of cylinders are not just numbers, but they are actually factors, so instead of working out the median and the five-number summary, it counts how many times each of these level occurs.\nIf we wish to do the same to model, trans, drv, fl and class, we can use a lovely convenience function called across(), which will apply the same function to all variables that we are stating, like so:\n\nmpg &lt;- mutate(mpg, across(c(model, trans, drv, fl, class), factor))\n\nLet’s see the result with glimpse() first and summary() as well.\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;fct&gt; a4, a4, a4, a4, a4, a4, a4, a4 quattro, a4 quattro, a4 qu…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;fct&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;fct&gt; auto(l5), manual(m5), manual(m6), auto(av), auto(l5), man…\n$ drv          &lt;fct&gt; f, f, f, f, f, f, f, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, r, …\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;fct&gt; p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, r, …\n$ class        &lt;fct&gt; compact, compact, compact, compact, compact, compact, com…\n\n\nWe can see here that the variables we have mutated across now are all labelled as “factors” (fct). Let’s see the summary as well now:\n\nsummary(mpg)\n\n manufacturer                       model         displ            year     \n Length:234         caravan 2wd        : 11   Min.   :1.600   Min.   :1999  \n Class :character   ram 1500 pickup 4wd: 10   1st Qu.:2.400   1st Qu.:1999  \n Mode  :character   civic              :  9   Median :3.300   Median :2004  \n                    dakota pickup 4wd  :  9   Mean   :3.472   Mean   :2004  \n                    jetta              :  9   3rd Qu.:4.600   3rd Qu.:2008  \n                    mustang            :  9   Max.   :7.000   Max.   :2008  \n                    (Other)            :177                                 \n cyl           trans    drv          cty             hwy        fl     \n 4:81   auto(l4)  :83   4:103   Min.   : 9.00   Min.   :12.00   c:  1  \n 5: 4   manual(m5):58   f:106   1st Qu.:14.00   1st Qu.:18.00   d:  5  \n 6:79   auto(l5)  :39   r: 25   Median :17.00   Median :24.00   e:  8  \n 8:70   manual(m6):19           Mean   :16.86   Mean   :23.44   p: 52  \n        auto(s6)  :16           3rd Qu.:19.00   3rd Qu.:27.00   r:168  \n        auto(l6)  : 6           Max.   :35.00   Max.   :44.00          \n        (Other)   :13                                                  \n        class   \n 2seater   : 5  \n compact   :47  \n midsize   :41  \n minivan   :11  \n pickup    :33  \n subcompact:35  \n suv       :62  \n\n\nThis is actually much more informative.\n\n\n\nBefore we can start learning all the beautiful and so helpful functions in the tidyverse, it becomes absolutely vital to talk about the philosophy of the tidyverse. The functions in tidyverse are generally defined with a verb (e.g. select, filter, mutate, rename, arrange, etc) and we generally take a data set, stored as a data frame or a tibble, and we apply one of these verb, then another and then another and so on, until we get what we need. The coding equivalent of the adverb “then” is called a pipe. The pipe command is the coding equivalent of the composition of functions in maths.\nIn maths, if f(x) and g(x) are two functions, instead of writing g(f(x)), i.e. to take x apply f and then apply g. In symbols,\n\nx \\mapsto f(x) \\mapsto g\\big(f(x)\\big),\n\nIn R, we do something similar: instead of taking g(f(x)), we do x |&gt; f |&gt; g using the |&gt; (pipe) command. So, for example, to say\n\nmpg &lt;- mutate(mpg, cyl = factor(cyl))\n\nwe can write\n\nmpg &lt;- mpg"
  },
  {
    "objectID": "data-frames.html#the-tidyverse",
    "href": "data-frames.html#the-tidyverse",
    "title": "Data Frames",
    "section": "",
    "text": "Quoting from the tidyverse home page:\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\nAs we have seen by loading the tidyverse, this meta-package is composed of 9 packages, each with a specific function, to make the code more readable, effective and data analysis more enjoyable.\nThe first feature of the tidyverse that we want to get acquainted with is a tibble. Again, quoting from the tidyverse home page: “A tibble is a modern re-imagining of the data frame, keeping what time has proven to be effective, and throwing out what it has not. Tibbles are data.frames that are lazy and surly: they do less and complain more forcing you to confront problems earlier, typically leading to cleaner, more expressive code.”"
  },
  {
    "objectID": "data-frames.html#tibbles",
    "href": "data-frames.html#tibbles",
    "title": "Data Frames",
    "section": "",
    "text": "Tibbles are represented as a special type of bivariate data sets, where every column may store different type of objects, but the overall length of each column must be the same. Tibbles may be thought of as two-by-two matrices, where the rows represent different items, and each column represents the variables that are recorded, or measured, for each item. Thus tibbles are the object that correctly represents a data set.\nTibbles are generally created by reading in a data set using the readr functions such as read_csv() or read_delim(). However, tibbles can also be created explicitly using the tibble() function. For example,\n\ntibble(\n    name = c(\"Alice\", \"Bob\", \"Charlie\"),\n    age = c(25, 31, 36),\n    salary = c(14000, 18000, 25000)\n)\n\n# A tibble: 3 × 3\n  name      age salary\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Alice      25  14000\n2 Bob        31  18000\n3 Charlie    36  25000\n\n\nThis is easy however, only when the variables (name, age and salary are already stored in some vectors, and we wish to collate them together into a data frame). When we try to store them one by one, it is often more logical to give the data row by row. This can be done with a variant of tibble called tribble(), like so:\n\ntribble(\n    ~ name, ~ age, ~ salary,\n    \"Alice\", 25, 14000,\n    \"Bob\", 21, 18000,\n    \"Charlie\", 56, 25000\n)\n\n# A tibble: 3 × 3\n  name      age salary\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Alice      25  14000\n2 Bob        21  18000\n3 Charlie    56  25000\n\n\nNote the presence of the symbol ~ before the names of the columns (i.e. the names of the variables) when defined using the tribble() function.\nGenerally speaking, the tribble() function works well when one wishes to write down the data directly, while the tibble() function works well to collect into a tibble different variables already stored into single vectors. For example, assume we have recorded the height (in cm) and the weight (in kg) of a sample of students and we have stored this information into the variables height and weight, like so:\n\nheight &lt;- c(163, 171, 159, 162, 161, 174, 177, 158, 164, 177)\nweight &lt;- c(65, 78, 73, 81, 83, 79, 80, 76, 82, 88)\n\nThen we can collect these variables into a tibble, like so:\n\nstudents &lt;- tibble(height, weight)\nstudents\n\n# A tibble: 10 × 2\n   height weight\n    &lt;dbl&gt;  &lt;dbl&gt;\n 1    163     65\n 2    171     78\n 3    159     73\n 4    162     81\n 5    161     83\n 6    174     79\n 7    177     80\n 8    158     76\n 9    164     82\n10    177     88\n\n\nNevertheless, it should be quite evident that when the data set is big, this is not the best way to create a data set. Before exploring how to import data sets into R, however, it may be worth exploring a few data sets."
  },
  {
    "objectID": "data-frames.html#installing-and-loading-packages-in-r",
    "href": "data-frames.html#installing-and-loading-packages-in-r",
    "title": "Data Frames",
    "section": "",
    "text": "Anyone can create new R packages, but only when packages satisfy certain strict rules are stored on CRAN. This ensures that packages stores on CRAN are reliable, have documentation and there is a support in place for the users. To install a package that lives on CRAN it suffices to type on the console install.packages(\"package_name\"). R will then install the package and all the dependencies needed to run the package.\nSo, to install the whole tidyverse we just have to type install.packages(\"tidyverse\").\nTo load a package (regardless of where it comes from), we need to use the command library(). So, to load the tidyverse we can just type in out script and run the code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThe outcome is pretty overwhelming! First we are informed that all the core tidyverse packages are correctly loaded: dplyr, forecats, ggplot2, lubridate, purrr, readr, stringr, tibble and tidyr. Then we are also informed that there are two functions that were already loaded from the package stats (a core package automatically loaded by R), and they are now substituted by the homonym functions from dplyr. This might seem like a loss, but the stats functions are not lost, we only need to call them via their “long name”.\n\n\nThe long name of a function is composed by the name of the package where the function is stored, two colons (::) and the name of the function. So, to use the function filter() in stats we can type stats::filter(). Similarly, if we wanted to use the function read_csv() which lies in the package readr, we could just type readr::read_csv() without the needs to load the package readr in advance.\n\n\n\n\n\n\nTip\n\n\n\nIt is good practice to always load at the beginning of the script code the packages that are going to be used, even though, sometimes, we may end up using the long name for the sake of clarity, or to avoid conflicts between packages."
  },
  {
    "objectID": "data-frames.html#examples-of-data-sets",
    "href": "data-frames.html#examples-of-data-sets",
    "title": "Data Frames",
    "section": "",
    "text": "R contains several examples of data sets, some of which particularly interesting because they are data sets of historical value, like the iris data set. To see which data sets are included in R, we can use the command data(). This opens a new tab in RStudio showing the list of data sets included in base R.\nAny of these data sets can be called simply typing their name on the console (or running the corresponding code in the R script). However, data sets stored in R cannot be changed, and in order to have the flexibility to make changes, we may wish to save a copy in the memory. However, since the base R saves data sets as data.frame type, we may wish to transform them into a tibble, with the command as_tibble(), like so:\n\niris &lt;- as_tibble(iris)\niris\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n\nNote that the data sets contains 150 rows, but one of the features of a tibble is that it shows only the first 10 rows. If we wish to see more (or less) rows, we can pass the tibble to the function print() and state the numbers of rows to print. For instance, to see the first three rows, we can use\n\nprint(iris, n = 3)\n\n# A tibble: 150 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n# ℹ 147 more rows\n\n\nIf we wish to see the structure of the variables of this data set, we can use the glimpse() function, which shows the list of the variables together with their type and the first few values of each of them. For example,\n\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nWe have also already established that the function summary() is adaptable and its outcome depends on the type of object that we pass to it. Let’s see what happens when we pass a tibble to this function.\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nNicely, summary() returns a summary of each variable in the tibble, and each summary depends on the type of the variable.\nAnother nice data set stored in R is airquality, which shows the Daily air quality measurements in New York, May to September 1973. To store it as a tibble, let’s run the following\n\nairquality &lt;- as_tibble(airquality)\nairquality\n\n# A tibble: 153 × 6\n   Ozone Solar.R  Wind  Temp Month   Day\n   &lt;int&gt;   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    41     190   7.4    67     5     1\n 2    36     118   8      72     5     2\n 3    12     149  12.6    74     5     3\n 4    18     313  11.5    62     5     4\n 5    NA      NA  14.3    56     5     5\n 6    28      NA  14.9    66     5     6\n 7    23     299   8.6    65     5     7\n 8    19      99  13.8    59     5     8\n 9     8      19  20.1    61     5     9\n10    NA     194   8.6    69     5    10\n# ℹ 143 more rows\n\n\nHere we can notice a feature that we have not seen before: the presence of NA’s into the data set. NA is a special type of logical value which stands for “Not Available”. This represents a missing value. It is often the case that a data set is incomplete, i.e. that some of the data is not recorded, or it is lost. If these situations are saved as NA, R can keep track of the missing value and handle it accordingly. There are several functions in R that help dealing with missing values.\nAnother example of data set comes from the package ggplot2 (one of the tidyverse core packages) and it is called mpg; it contains the Fuel economy data from 1999 to 2008 for 38 popular models of cars. This is a data set stored into the tidyverse so it is already a tibble. To see it we can just call it, like so:\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\nAn interesting fact about this data set is the variety of variables stored in it. Let’s have a proper look with glimpse():\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\nLet’s also use summary() to have a look at a summary of these values.\n\nsummary(mpg)\n\n manufacturer          model               displ            year     \n Length:234         Length:234         Min.   :1.600   Min.   :1999  \n Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999  \n Mode  :character   Mode  :character   Median :3.300   Median :2004  \n                                       Mean   :3.472   Mean   :2004  \n                                       3rd Qu.:4.600   3rd Qu.:2008  \n                                       Max.   :7.000   Max.   :2008  \n      cyl           trans               drv                 cty       \n Min.   :4.000   Length:234         Length:234         Min.   : 9.00  \n 1st Qu.:4.000   Class :character   Class :character   1st Qu.:14.00  \n Median :6.000   Mode  :character   Mode  :character   Median :17.00  \n Mean   :5.889                                         Mean   :16.86  \n 3rd Qu.:8.000                                         3rd Qu.:19.00  \n Max.   :8.000                                         Max.   :35.00  \n      hwy             fl               class          \n Min.   :12.00   Length:234         Length:234        \n 1st Qu.:18.00   Class :character   Class :character  \n Median :24.00   Mode  :character   Mode  :character  \n Mean   :23.44                                        \n 3rd Qu.:27.00                                        \n Max.   :44.00                                        \n\n\nA quick look shows that most of these summaries is little informative. For example, the number of cylinders, cyl, really not helpful to understand what is going on. Same for the model, which only tells us that there are 234 data, bat what is the distribution of the models?\nTo answer that, we need to explain R that some of these data are not just characters (or numbers), but they are “categorical data”, which R calls factors."
  },
  {
    "objectID": "data-frames.html#factors",
    "href": "data-frames.html#factors",
    "title": "Data Frames",
    "section": "",
    "text": "Factors are categorical data, i.e. qualitative or non-numerical data. For instance, social class, primary diagnosis, tumor stage, Tanner stage of puberty, etc are all examples of categorical data. They are typically input using a numeric code, but they can also be stored as characters.\nSuch variables should always be specified as factor in R. This is the data structure that (among other things) makes it possible to assign meaningful names to the categories, instead of reading them as mere strings of characters (such as IDs).\nThe terminology is that a factor has a set of levels — say four levels for concreteness. Internally, a four-level factor consists of two items: (a) a vector of integers between 1 and 4, and (b) a character vector of length 4 containing strings describing what the four levels are. Let’s look at an example, before going back to the mpg data set.\n\npain &lt;- c(0, 3, 2, 2, 1)\nfpain &lt;- factor(pain, levels = 0:3)\nlevels(fpain) &lt;- c(\"none\", \"mild\", \"medium\", \"severe\")\n\npain\n\n[1] 0 3 2 2 1\n\nfpain\n\n[1] none   severe medium medium mild  \nLevels: none mild medium severe\n\n\nThe first command creates a numeric vector pain, encoding the pain levels of five patients. We wish to treat this as categorical variable, so we create a factor fpain from it using the function factor(). This is called with one argument in addition to pain, namely levels = 0:3, which indicates that the input coding uses the values 0 to 3. The latter can in principle be left out since R by default uses the values in pain, suitably sorted, but it is a good habit to retain it. The effect of the final line is that the level names are changed to the four specified character strings.\nNow let’s return to the mpg data set. We wish to convert the variable cyl to factor. To do so, let’s use some powerful features of the tidyverse, and in particular of the package dplyr. Precisely, we can “mutate” the variable cyl transforming it into a factor, using the function mutate(), like so:\n\nmpg &lt;- mutate(mpg, cyl = factor(cyl))\n\nWe can now see what happens calling the summary() again.\n\nsummary(mpg)\n\n manufacturer          model               displ            year      cyl   \n Length:234         Length:234         Min.   :1.600   Min.   :1999   4:81  \n Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999   5: 4  \n Mode  :character   Mode  :character   Median :3.300   Median :2004   6:79  \n                                       Mean   :3.472   Mean   :2004   8:70  \n                                       3rd Qu.:4.600   3rd Qu.:2008         \n                                       Max.   :7.000   Max.   :2008         \n    trans               drv                 cty             hwy       \n Length:234         Length:234         Min.   : 9.00   Min.   :12.00  \n Class :character   Class :character   1st Qu.:14.00   1st Qu.:18.00  \n Mode  :character   Mode  :character   Median :17.00   Median :24.00  \n                                       Mean   :16.86   Mean   :23.44  \n                                       3rd Qu.:19.00   3rd Qu.:27.00  \n                                       Max.   :35.00   Max.   :44.00  \n      fl               class          \n Length:234         Length:234        \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nNow, correctly, R recognises that the number of cylinders are not just numbers, but they are actually factors, so instead of working out the median and the five-number summary, it counts how many times each of these level occurs.\nIf we wish to do the same to model, trans, drv, fl and class, we can use a lovely convenience function called across(), which will apply the same function to all variables that we are stating, like so:\n\nmpg &lt;- mutate(mpg, across(c(model, trans, drv, fl, class), factor))\n\nLet’s see the result with glimpse() first and summary() as well.\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;fct&gt; a4, a4, a4, a4, a4, a4, a4, a4 quattro, a4 quattro, a4 qu…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;fct&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;fct&gt; auto(l5), manual(m5), manual(m6), auto(av), auto(l5), man…\n$ drv          &lt;fct&gt; f, f, f, f, f, f, f, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, r, …\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;fct&gt; p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, r, …\n$ class        &lt;fct&gt; compact, compact, compact, compact, compact, compact, com…\n\n\nWe can see here that the variables we have mutated across now are all labelled as “factors” (fct). Let’s see the summary as well now:\n\nsummary(mpg)\n\n manufacturer                       model         displ            year     \n Length:234         caravan 2wd        : 11   Min.   :1.600   Min.   :1999  \n Class :character   ram 1500 pickup 4wd: 10   1st Qu.:2.400   1st Qu.:1999  \n Mode  :character   civic              :  9   Median :3.300   Median :2004  \n                    dakota pickup 4wd  :  9   Mean   :3.472   Mean   :2004  \n                    jetta              :  9   3rd Qu.:4.600   3rd Qu.:2008  \n                    mustang            :  9   Max.   :7.000   Max.   :2008  \n                    (Other)            :177                                 \n cyl           trans    drv          cty             hwy        fl     \n 4:81   auto(l4)  :83   4:103   Min.   : 9.00   Min.   :12.00   c:  1  \n 5: 4   manual(m5):58   f:106   1st Qu.:14.00   1st Qu.:18.00   d:  5  \n 6:79   auto(l5)  :39   r: 25   Median :17.00   Median :24.00   e:  8  \n 8:70   manual(m6):19           Mean   :16.86   Mean   :23.44   p: 52  \n        auto(s6)  :16           3rd Qu.:19.00   3rd Qu.:27.00   r:168  \n        auto(l6)  : 6           Max.   :35.00   Max.   :44.00          \n        (Other)   :13                                                  \n        class   \n 2seater   : 5  \n compact   :47  \n midsize   :41  \n minivan   :11  \n pickup    :33  \n subcompact:35  \n suv       :62  \n\n\nThis is actually much more informative."
  },
  {
    "objectID": "data-frames.html#some-advanced-features-of-tidyverse",
    "href": "data-frames.html#some-advanced-features-of-tidyverse",
    "title": "Data Frames",
    "section": "",
    "text": "Before we can start learning all the beautiful and so helpful functions in the tidyverse, it becomes absolutely vital to talk about the philosophy of the tidyverse. The functions in tidyverse are generally defined with a verb (e.g. select, filter, mutate, rename, arrange, etc) and we generally take a data set, stored as a data frame or a tibble, and we apply one of these verb, then another and then another and so on, until we get what we need. The coding equivalent of the adverb “then” is called a pipe. The pipe command is the coding equivalent of the composition of functions in maths.\nIn maths, if f(x) and g(x) are two functions, instead of writing g(f(x)), i.e. to take x apply f and then apply g. In symbols,\n\nx \\mapsto f(x) \\mapsto g\\big(f(x)\\big),\n\nIn R, we do something similar: instead of taking g(f(x)), we do x |&gt; f |&gt; g using the |&gt; (pipe) command. So, for example, to say\n\nmpg &lt;- mutate(mpg, cyl = factor(cyl))\n\nwe can write\n\nmpg &lt;- mpg"
  }
]